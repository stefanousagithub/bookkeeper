<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TransactionalEntryLogCompactor.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache BookKeeper :: Server</a> &gt; <a href="index.source.html" class="el_package">org.apache.bookkeeper.bookie</a> &gt; <span class="el_source">TransactionalEntryLogCompactor.java</span></div><h1>TransactionalEntryLogCompactor.java</h1><pre class="source lang-java linenums">/*
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 */

package org.apache.bookkeeper.bookie;

import io.netty.buffer.ByteBuf;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import org.apache.bookkeeper.bookie.storage.CompactionEntryLog;
import org.apache.bookkeeper.bookie.storage.EntryLogScanner;
import org.apache.bookkeeper.bookie.storage.EntryLogger;
import org.apache.bookkeeper.conf.ServerConfiguration;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This class is used for compaction. Compaction is done in several transactional phases.
 * Phase 1: Scan old entry log and compact entries to a new .compacting log file.
 * Phase 2: Flush .compacting log to disk and it becomes .compacted log file when this completes.
 * Phase 3: Flush ledger cache and .compacted file becomes .log file when this completes. Remove old
 * entry log file afterwards.
 */
public class TransactionalEntryLogCompactor extends AbstractLogCompactor {

<span class="nc" id="L44">    private static final Logger LOG = LoggerFactory.getLogger(TransactionalEntryLogCompactor.class);</span>

    final EntryLogger entryLogger;
    final CompactableLedgerStorage ledgerStorage;
<span class="nc" id="L48">    final List&lt;EntryLocation&gt; offsets = new ArrayList&lt;&gt;();</span>

    // compaction log file suffix
    public static final String COMPACTING_SUFFIX = &quot;.log.compacting&quot;;
    // flushed compaction log file suffix
    public static final String COMPACTED_SUFFIX = &quot;.compacted&quot;;

    public TransactionalEntryLogCompactor(
            ServerConfiguration conf,
            EntryLogger entryLogger,
            CompactableLedgerStorage ledgerStorage,
            LogRemovalListener logRemover) {
<span class="nc" id="L60">        super(conf, logRemover);</span>
<span class="nc" id="L61">        this.entryLogger = entryLogger;</span>
<span class="nc" id="L62">        this.ledgerStorage = ledgerStorage;</span>
<span class="nc" id="L63">    }</span>

    /**
     * Delete all previously incomplete compacting logs and recover the index for compacted logs.
     */
    @Override
    public void cleanUpAndRecover() {
        // clean up compacting logs and recover index for already compacted logs
<span class="nc bnc" id="L71" title="All 2 branches missed.">        for (CompactionEntryLog log : entryLogger.incompleteCompactionLogs()) {</span>
<span class="nc" id="L72">            LOG.info(&quot;Found compacted log file {} has partially flushed index, recovering index.&quot;, log);</span>
<span class="nc" id="L73">            CompactionPhase updateIndex = new UpdateIndexPhase(log, true);</span>
<span class="nc" id="L74">            updateIndex.run();</span>
<span class="nc" id="L75">        }</span>
<span class="nc" id="L76">    }</span>

    @Override
    public boolean compact(EntryLogMetadata metadata) {
<span class="nc bnc" id="L80" title="All 2 branches missed.">        if (metadata != null) {</span>
<span class="nc" id="L81">            LOG.info(&quot;Compacting entry log {} with usage {}.&quot;,</span>
<span class="nc" id="L82">                metadata.getEntryLogId(), metadata.getUsage());</span>
            CompactionEntryLog compactionLog;
            try {
<span class="nc" id="L85">                compactionLog = entryLogger.newCompactionLog(metadata.getEntryLogId());</span>
<span class="nc" id="L86">            } catch (IOException ioe) {</span>
<span class="nc" id="L87">                LOG.error(&quot;Exception creating new compaction entry log&quot;, ioe);</span>
<span class="nc" id="L88">                return false;</span>
<span class="nc" id="L89">            }</span>
<span class="nc" id="L90">            CompactionPhase scanEntryLog = new ScanEntryLogPhase(metadata, compactionLog);</span>
<span class="nc bnc" id="L91" title="All 2 branches missed.">            if (!scanEntryLog.run()) {</span>
<span class="nc" id="L92">                LOG.info(&quot;Compaction for entry log {} end in ScanEntryLogPhase.&quot;, metadata.getEntryLogId());</span>
<span class="nc" id="L93">                return false;</span>
            }

<span class="nc" id="L96">            CompactionPhase flushCompactionLog = new FlushCompactionLogPhase(compactionLog);</span>
<span class="nc bnc" id="L97" title="All 2 branches missed.">            if (!flushCompactionLog.run()) {</span>
<span class="nc" id="L98">                LOG.info(&quot;Compaction for entry log {} end in FlushCompactionLogPhase.&quot;, metadata.getEntryLogId());</span>
<span class="nc" id="L99">                return false;</span>
            }

<span class="nc" id="L102">            CompactionPhase updateIndex = new UpdateIndexPhase(compactionLog);</span>
<span class="nc bnc" id="L103" title="All 2 branches missed.">            if (!updateIndex.run()) {</span>
<span class="nc" id="L104">                LOG.info(&quot;Compaction for entry log {} end in UpdateIndexPhase.&quot;, metadata.getEntryLogId());</span>
<span class="nc" id="L105">                return false;</span>
            }
<span class="nc" id="L107">            LOG.info(&quot;Compacted entry log : {}.&quot;, metadata.getEntryLogId());</span>
<span class="nc" id="L108">            return true;</span>
        }
<span class="nc" id="L110">        return false;</span>
    }

    /**
     * An abstract class that would be extended to be the actual transactional phases for compaction.
     */
    abstract static class CompactionPhase {
<span class="nc" id="L117">        private String phaseName = &quot;&quot;;</span>

<span class="nc" id="L119">        CompactionPhase(String phaseName) {</span>
<span class="nc" id="L120">            this.phaseName = phaseName;</span>
<span class="nc" id="L121">        }</span>

        boolean run() {
            try {
<span class="nc" id="L125">                start();</span>
<span class="nc" id="L126">                return complete();</span>
<span class="nc" id="L127">            } catch (IOException e) {</span>
<span class="nc" id="L128">                LOG.error(&quot;Encounter exception in compaction phase {}. Abort current compaction.&quot;, phaseName, e);</span>
<span class="nc" id="L129">                abort();</span>
            }
<span class="nc" id="L131">            return false;</span>
        }

        abstract void start() throws IOException;

        abstract boolean complete() throws IOException;

        abstract void abort();

    }

    /**
     * Assume we're compacting entry log 1 to entry log 3.
     * The first phase is to scan entries in 1.log and copy them to compaction log file &quot;3.log.compacting&quot;.
     * We'll try to allocate a new compaction log before scanning to make sure we have a log file to write.
     * If after scanning, there's no data written, it means there's no valid entries to be compacted,
     * so we can remove 1.log directly, clear the offsets and end the compaction.
     * Otherwise, we should move on to the next phase.
     *
     * &lt;p&gt;If anything failed in this phase, we should delete the compaction log and clean the offsets.
     */
    class ScanEntryLogPhase extends CompactionPhase {
        private final EntryLogMetadata metadata;
        private final CompactionEntryLog compactionLog;

<span class="nc" id="L156">        ScanEntryLogPhase(EntryLogMetadata metadata, CompactionEntryLog compactionLog) {</span>
<span class="nc" id="L157">            super(&quot;ScanEntryLogPhase&quot;);</span>
<span class="nc" id="L158">            this.metadata = metadata;</span>
<span class="nc" id="L159">            this.compactionLog = compactionLog;</span>
<span class="nc" id="L160">        }</span>

        @Override
        void start() throws IOException {
            // scan entry log into compaction log and offset list
<span class="nc" id="L165">            entryLogger.scanEntryLog(metadata.getEntryLogId(), new EntryLogScanner() {</span>
                @Override
                public boolean accept(long ledgerId) {
<span class="nc" id="L168">                    return metadata.containsLedger(ledgerId);</span>
                }

                @Override
                public void process(long ledgerId, long offset, ByteBuf entry) throws IOException {
<span class="nc" id="L173">                    throttler.acquire(entry.readableBytes());</span>
<span class="nc" id="L174">                    synchronized (TransactionalEntryLogCompactor.this) {</span>
<span class="nc" id="L175">                        long lid = entry.getLong(entry.readerIndex());</span>
<span class="nc" id="L176">                        long entryId = entry.getLong(entry.readerIndex() + 8);</span>
<span class="nc bnc" id="L177" title="All 4 branches missed.">                        if (lid != ledgerId || entryId &lt; -1) {</span>
<span class="nc" id="L178">                            LOG.warn(&quot;Scanning expected ledgerId {}, but found invalid entry &quot;</span>
                                    + &quot;with ledgerId {} entryId {} at offset {}&quot;,
<span class="nc" id="L180">                                    ledgerId, lid, entryId, offset);</span>
<span class="nc" id="L181">                            throw new IOException(&quot;Invalid entry found @ offset &quot; + offset);</span>
                        }
<span class="nc" id="L183">                        long newOffset = compactionLog.addEntry(ledgerId, entry);</span>
<span class="nc" id="L184">                        offsets.add(new EntryLocation(ledgerId, entryId, newOffset));</span>

<span class="nc bnc" id="L186" title="All 2 branches missed.">                        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L187">                            LOG.debug(&quot;Compact add entry : lid = {}, eid = {}, offset = {}&quot;,</span>
<span class="nc" id="L188">                                    ledgerId, entryId, newOffset);</span>
                        }
<span class="nc" id="L190">                    }</span>
<span class="nc" id="L191">                }</span>
            });
<span class="nc" id="L193">        }</span>

        @Override
        boolean complete() {
<span class="nc bnc" id="L197" title="All 2 branches missed.">            if (offsets.isEmpty()) {</span>
                // no valid entries is compacted, delete entry log file
<span class="nc" id="L199">                LOG.info(&quot;No valid entry is found in entry log after scan, removing entry log now.&quot;);</span>
<span class="nc" id="L200">                logRemovalListener.removeEntryLog(metadata.getEntryLogId());</span>
<span class="nc" id="L201">                compactionLog.abort();</span>
<span class="nc" id="L202">                return false;</span>
            }
<span class="nc" id="L204">            return true;</span>
        }

        @Override
        void abort() {
<span class="nc" id="L209">            offsets.clear();</span>
            // since we haven't flushed yet, we only need to delete the unflushed compaction file.
<span class="nc" id="L211">            compactionLog.abort();</span>
<span class="nc" id="L212">        }</span>
    }

    /**
     * Assume we're compacting log 1 to log 3.
     * This phase is to flush the compaction log.
     * When this phase starts, there should be a compaction log file like &quot;3.log.compacting&quot;
     * When compaction log is flushed, in order to indicate this phase is completed,
     * a hardlink file &quot;3.log.1.compacted&quot; should be created, and &quot;3.log.compacting&quot; should be deleted.
     */
    class FlushCompactionLogPhase extends CompactionPhase {
        final CompactionEntryLog compactionLog;

<span class="nc" id="L225">        FlushCompactionLogPhase(CompactionEntryLog compactionLog) {</span>
<span class="nc" id="L226">            super(&quot;FlushCompactionLogPhase&quot;);</span>
<span class="nc" id="L227">            this.compactionLog = compactionLog;</span>
<span class="nc" id="L228">        }</span>

        @Override
        void start() throws IOException {
            // flush the current compaction log.
<span class="nc" id="L233">            compactionLog.flush();</span>
<span class="nc" id="L234">        }</span>

        @Override
        boolean complete() throws IOException {
            try {
<span class="nc" id="L239">                compactionLog.markCompacted();</span>
<span class="nc" id="L240">                return true;</span>
<span class="nc" id="L241">            } catch (IOException ioe) {</span>
<span class="nc" id="L242">                LOG.warn(&quot;Error marking compaction as done&quot;, ioe);</span>
<span class="nc" id="L243">                return false;</span>
            }
        }

        @Override
        void abort() {
<span class="nc" id="L249">            offsets.clear();</span>
            // remove compaction log file and its hardlink
<span class="nc" id="L251">            compactionLog.abort();</span>
<span class="nc" id="L252">        }</span>
    }

    /**
     * Assume we're compacting log 1 to log 3.
     * This phase is to update the entry locations and flush the index.
     * When the phase start, there should be a compacted file like &quot;3.log.1.compacted&quot;,
     * where 3 is the new compaction logId and 1 is the old entry logId.
     * After the index the flushed successfully, a hardlink &quot;3.log&quot; file should be created,
     * and 3.log.1.compacted file should be deleted to indicate the phase is succeed.
     *
     * &lt;p&gt;This phase can also used to recover partially flushed index when we pass isInRecovery=true
     */
    class UpdateIndexPhase extends CompactionPhase {
        final CompactionEntryLog compactionLog;
        private final boolean isInRecovery;

        public UpdateIndexPhase(CompactionEntryLog compactionLog) {
<span class="nc" id="L270">            this(compactionLog, false);</span>
<span class="nc" id="L271">        }</span>

<span class="nc" id="L273">        public UpdateIndexPhase(CompactionEntryLog compactionLog, boolean isInRecovery) {</span>
<span class="nc" id="L274">            super(&quot;UpdateIndexPhase&quot;);</span>
<span class="nc" id="L275">            this.compactionLog = compactionLog;</span>
<span class="nc" id="L276">            this.isInRecovery = isInRecovery;</span>
<span class="nc" id="L277">        }</span>

        @Override
        void start() throws IOException {
<span class="nc" id="L281">            compactionLog.makeAvailable();</span>
<span class="nc bnc" id="L282" title="All 2 branches missed.">            if (isInRecovery) {</span>
<span class="nc" id="L283">                recoverEntryLocations(compactionLog);</span>
            }
<span class="nc bnc" id="L285" title="All 2 branches missed.">            if (!offsets.isEmpty()) {</span>
                // update entry locations and flush index
<span class="nc" id="L287">                ledgerStorage.updateEntriesLocations(offsets);</span>
<span class="nc" id="L288">                ledgerStorage.flushEntriesLocationsIndex();</span>
            }
<span class="nc" id="L290">        }</span>

        @Override
        boolean complete() {
            // When index is flushed, and entry log is removed,
            // delete the &quot;.compacted&quot; file to indicate this phase is completed.
<span class="nc" id="L296">            offsets.clear();</span>
<span class="nc" id="L297">            compactionLog.finalizeAndCleanup();</span>
<span class="nc" id="L298">            logRemovalListener.removeEntryLog(compactionLog.getSrcLogId());</span>
<span class="nc" id="L299">            return true;</span>
        }

        @Override
        void abort() {
<span class="nc" id="L304">            offsets.clear();</span>
<span class="nc" id="L305">        }</span>

        /**
         * Scan entry log to recover entry locations.
         */
        private void recoverEntryLocations(CompactionEntryLog compactionLog) throws IOException {
<span class="nc" id="L311">            compactionLog.scan(new EntryLogScanner() {</span>
                @Override
                public boolean accept(long ledgerId) {
<span class="nc" id="L314">                    return true;</span>
                }

                @Override
                public void process(long ledgerId, long offset, ByteBuf entry) throws IOException {
<span class="nc" id="L319">                    long lid = entry.getLong(entry.readerIndex());</span>
<span class="nc" id="L320">                    long entryId = entry.getLong(entry.readerIndex() + 8);</span>
<span class="nc bnc" id="L321" title="All 4 branches missed.">                    if (lid != ledgerId || entryId &lt; -1) {</span>
<span class="nc" id="L322">                        LOG.warn(&quot;Scanning expected ledgerId {}, but found invalid entry &quot;</span>
                                + &quot;with ledgerId {} entryId {} at offset {}&quot;,
<span class="nc" id="L324">                                ledgerId, lid, entryId, offset);</span>
<span class="nc" id="L325">                        throw new IOException(&quot;Invalid entry found @ offset &quot; + offset);</span>
                    }
<span class="nc" id="L327">                    long location = (compactionLog.getDstLogId() &lt;&lt; 32L) | (offset + 4);</span>
<span class="nc" id="L328">                    offsets.add(new EntryLocation(lid, entryId, location));</span>
<span class="nc" id="L329">                }</span>
            });
<span class="nc" id="L331">            LOG.info(&quot;Recovered {} entry locations from compacted log {}&quot;, offsets.size(), compactionLog.getDstLogId());</span>
<span class="nc" id="L332">        }</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.10.202304240956</span></div></body></html>